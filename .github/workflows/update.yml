name: Update Data

on:
  workflow_dispatch:       # Ermöglicht den manuellen Start per Button
  schedule:
    - cron: '0 4 * * *'    # Automatisch jeden Tag um 04:00 Uhr

permissions:
  contents: write

jobs:
  build:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3

      - name: Python Setup
        uses: actions/setup-python@v4
        with:
          python-version: '3.9'

      - name: Download Data
        run: |
          # 1. WIKIDATA (Deine Query)
          curl -G "https://query.wikidata.org/sparql" \
            --data-urlencode "query=SELECT DISTINCT ?qid ?lat ?lon ?label WHERE { ?item wdt:P131* wd:Q15124; wdt:P625 ?loc . BIND(STRAFTER(STR(?item), '/entity/') as ?qid) BIND(geof:latitude(?loc) as ?lat) BIND(geof:longitude(?loc) as ?lon) OPTIONAL { ?item rdfs:label ?label. FILTER(lang(?label)='de') } }" \
            -H "Accept: text/csv" > query.csv
          
          # 2. OSM (Deine Query - angepasst mit fester Area ID für Server)
          # timeout 300, area Südtirol ID: 3600016240
          curl -d "data=[out:json][timeout:300];area(id:3600016240)->.searchArea;nwr[~'.*wikidata$'~'.'](area.searchArea);out tags;" \
            "https://overpass-api.de/api/interpreter" > osm.json

      - name: Run Processing
        run: python abgleich.py

      - name: Commit & Push
        run: |
          git config --global user.name 'UpdateBot'
          git config --global user.email 'bot@noreply.github.com'
          git add data.geojson
          git commit -m "Update Data" || exit 0
          # Rebase Strategie verhindert Konflikte
          git pull --rebase -Xtheirs origin main
          git push
